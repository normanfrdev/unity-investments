import streamlit as st
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import re
from stop_words import get_stop_words
import os
import random
from wordcloud import WordCloud
import datetime

st.set_page_config(layout="wide")
st.title("üá∑üá∫ –ê–Ω–∞–ª–∏–∑ —á–∞—Ç–∞ Telegram –≥—Ä—É–ø–ø—ã —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏")

# –ó–∞–≥—Ä—É–∂–∞–µ–º JSON —Ñ–∞–π–ª result.json –∏–∑ –ø–∞–ø–∫–∏ —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º
json_path = os.path.join(os.path.dirname(__file__), "result.json")

if not os.path.exists(json_path):
    st.error("–§–∞–π–ª 'result.json' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–∞–ø–∫–µ —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º.")
    st.stop()

with open(json_path, "r", encoding="utf-8") as f:
    data = json.load(f)

messages = data.get("messages", [])

rows = []
for msg in messages:
    if msg.get("type") != "message":
        continue
    sender = msg.get("from", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π")
    date = msg.get("date")
    text = msg.get("text")
    media = None
    if "photo" in msg:
        media = "—Ñ–æ—Ç–æ"
    elif "file" in msg:
        media = "—Ñ–∞–π–ª"
    elif msg.get("media_type") == "animation":
        media = "–∞–Ω–∏–º–∞—Ü–∏—è"

    if isinstance(text, list):
        new_text = []
        for t in text:
            if isinstance(t, str):
                new_text.append(t)
            elif isinstance(t, dict):
                new_text.append(t.get("text", ""))
        text = "".join(new_text)

    rows.append({
        "sender": sender,
        "date": date,
        "text": text,
        "media": media,
    })

raw_df = pd.DataFrame(rows)
raw_df["date"] = pd.to_datetime(raw_df["date"])
raw_df["day"] = raw_df["date"].dt.date
raw_df["hour"] = raw_df["date"].dt.hour
raw_df["weekday"] = raw_df["date"].dt.day_name()


excluded_patterns = [
    r"ID-C",
    r"‡£ß+"
]

mask = pd.Series([False]*len(raw_df))
for pattern in excluded_patterns:
    mask |= raw_df["sender"].astype(str).str.contains(pattern, regex=True, na=False)

df = raw_df[~mask].reset_index(drop=True)

# –§–∏–ª—å—Ç—Ä—ã –≤ —Å–∞–π–¥–±–∞—Ä–µ
users = sorted(df["sender"].dropna().unique())
filtered_df = df.copy()

# –°–∞–º—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏
st.subheader("üë§ –°–∞–º—ã–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏")
st.bar_chart(df["sender"].value_counts().head(10))

# –°–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–Ω—è–º
st.subheader("üïí –°–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–Ω—è–º")
daily_counts = df.groupby("day").size()
st.line_chart(daily_counts)

# –°–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏
st.subheader("üìÖ –°–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏")
weekday_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
weekday_counts = df["weekday"].value_counts().reindex(weekday_order)
plt.figure(figsize=(8, 4))
sns.barplot(x=weekday_counts.index, y=weekday_counts.values, palette="pastel")
plt.xticks(rotation=45)
plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π")
plt.title("–°–æ–æ–±—â–µ–Ω–∏—è –ø–æ –¥–Ω—è–º –Ω–µ–¥–µ–ª–∏")
st.pyplot(plt.gcf())

# –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ 
st.subheader("‚åö –¢–µ–ø–ª–æ–≤–∞—è –∫–∞—Ä—Ç–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ —á–∞—Å–∞–º")
heatmap_data = df.groupby(["hour", "sender"]).size().unstack(fill_value=0)
plt.figure(figsize=(12, 6))
sns.heatmap(heatmap_data, cmap="YlGnBu")
st.pyplot(plt.gcf())

# –ú–µ–¥–∏–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö
st.subheader("üìé –ú–µ–¥–∏–∞ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö")
media_counts = df["media"].value_counts()
st.bar_chart(media_counts)

# –°–∞–º—ã–µ —É–ø–æ—Ç—Ä–µ–±–ª—è–µ–º—ã–µ —Å–ª–æ–≤–∞ (—Ä—É—Å—Å–∫–∏–π)
st.subheader("üí¨ –°–∞–º—ã–µ —É–ø–æ—Ç—Ä–µ–±–ª—è–µ–º—ã–µ —Å–ª–æ–≤–∞ (—Ä—É—Å—Å–∫–∏–π)")
all_text = " ".join(filtered_df["text"].dropna().astype(str))
words = re.findall(r"\b\w+\b", all_text.lower())
stopwords_ru = set(get_stop_words("russian"))
words = [w for w in words if w not in stopwords_ru and len(w) > 2]
common_words = Counter(words).most_common(20)
word_df = pd.DataFrame(common_words, columns=["–°–ª–æ–≤–æ", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"])
plt.figure(figsize=(8, 5))
sns.barplot(data=word_df, y="–°–ª–æ–≤–æ", x="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", palette="viridis")
st.pyplot(plt.gcf())

# –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
st.subheader("‚úçÔ∏è –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º")
df["msg_length"] = df["text"].fillna("").apply(len)
avg_len = df.groupby("sender")["msg_length"].mean().sort_values(ascending=False).head(10)
plt.figure(figsize=(8, 4))
sns.barplot(x=avg_len.values, y=avg_len.index, palette="mako")
plt.xlabel("–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è (—Å–∏–º–≤–æ–ª—ã)")
st.pyplot(plt.gcf())

# –¢–æ–ø —Å–ª–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–ª–∏ –ø–æ –≤—Å–µ–º
st.subheader("üî§ –¢–æ–ø —Å–ª–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–ª–∏ –ø–æ –≤—Å–µ–º—É —á–∞—Ç—É")
target_user = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è", ["–í–µ—Å—å —á–∞—Ç"] + users)
if target_user == "–í–µ—Å—å —á–∞—Ç":
    target_df = df
else:
    target_df = df[df["sender"] == target_user]

all_text_user = " ".join(target_df["text"].dropna().astype(str))
words_user = re.findall(r"\b\w+\b", all_text_user.lower())
words_user = [w for w in words_user if w not in stopwords_ru and len(w) > 2]
common_words_user = Counter(words_user).most_common(20)
word_user_df = pd.DataFrame(common_words_user, columns=["–°–ª–æ–≤–æ", "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ"])
plt.figure(figsize=(8, 5))
sns.barplot(data=word_user_df, y="–°–ª–æ–≤–æ", x="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ", palette="coolwarm")
plt.title(f"–¢–æ–ø —Å–ª–æ–≤ –¥–ª—è {target_user}")
st.pyplot(plt.gcf())

# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏–π
st.subheader("üìè –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏–π")
plt.figure(figsize=(8, 4))
sns.histplot(df["msg_length"], bins=30, kde=True)
plt.xlabel("–î–ª–∏–Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è (—Å–∏–º–≤–æ–ª—ã)")
plt.title("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏–π")
st.pyplot(plt.gcf())

# –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ–±—â–µ–Ω–∏–π —Å –º–µ–¥–∏–∞
st.subheader("üìä –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ–±—â–µ–Ω–∏–π —Å –º–µ–¥–∏–∞")
total_msgs = len(df)
media_msgs = df["media"].notna().sum()
media_pct = media_msgs / total_msgs * 100
st.write(f"–°–æ–æ–±—â–µ–Ω–∏–π —Å –º–µ–¥–∏–∞: {media_msgs} / {total_msgs} ({media_pct:.2f}%)")

# –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ —á–∞—Å–∞–º
st.subheader("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ —á–∞—Å–∞–º")
hourly_counts = df.groupby("hour").size()
plt.figure(figsize=(10, 4))
sns.lineplot(x=hourly_counts.index, y=hourly_counts.values)
plt.xticks(range(0, 24))
plt.xlabel("–ß–∞—Å –¥–Ω—è")
plt.ylabel("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π")
plt.title("–°–æ–æ–±—â–µ–Ω–∏—è –ø–æ —á–∞—Å–∞–º")
st.pyplot(plt.gcf())

# === –ù–æ–≤—ã–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ===

# –°–ª—É—á–∞–π–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞ –≤—ã–±—Ä–∞–Ω–Ω—É—é –¥–∞—Ç—É
st.subheader("üé≤ –°–ª—É—á–∞–π–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞ –¥–∞—Ç—É")
min_date = df["date"].min().date()
max_date = df["date"].max().date()

selected_date = st.date_input(
    "–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç—É", 
    min_value=min_date, 
    max_value=max_date,
    value=min_date
)

msgs_on_date = df[df["date"].dt.date == selected_date]
if not msgs_on_date.empty:
    rand_msg = msgs_on_date.sample(1).iloc[0]
    st.markdown(f"**–û—Ç:** {rand_msg['sender']}  \n**–í—Ä–µ–º—è:** {rand_msg['date']}  \n\n{rand_msg['text']}")
else:
    st.write("–í —ç—Ç–æ—Ç –¥–µ–Ω—å —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ—Ç.")

# –°–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
st.subheader("–°–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
longest_msg = df.loc[df["msg_length"].idxmax()]
st.markdown(f"**–û—Ç:** {longest_msg['sender']}  \n**–î–ª–∏–Ω–∞:** {longest_msg['msg_length']} —Å–∏–º–≤–æ–ª–æ–≤  \n**–í—Ä–µ–º—è:** {longest_msg['date']}  \n\n{longest_msg['text']}")

# –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–µ–Ω—å
st.subheader("–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –¥–µ–Ω—å")
avg_msgs_day = daily_counts.mean()
st.write(f"{avg_msgs_day:.2f}")

# –¢–æ–ø 5 –¥–Ω–µ–π —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é (—Ä–∞–∑–≥–æ–≤–æ—Ä—ã-–±—É—Ä—Å—Ç—ã)
st.subheader("üî• –¢–æ–ø 5 –¥–Ω–µ–π —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å—é")
top_bursts = daily_counts.sort_values(ascending=False).head(5)
for day, count in top_bursts.items():
    st.write(f"{day}: {count} —Å–æ–æ–±—â–µ–Ω–∏–π")

# –û–±–ª–∞–∫–æ —Å–ª–æ–≤ –ø–æ —Å–∞–º—ã–º —á–∞—Å—Ç–æ—Ç–Ω—ã–º —Å–ª–æ–≤–∞–º
st.subheader("‚òÅÔ∏è –û–±–ª–∞–∫–æ —Å–ª–æ–≤ –ø–æ —Å–∞–º—ã–º —á–∞—Å—Ç–æ—Ç–Ω—ã–º —Å–ª–æ–≤–∞–º")

wordcloud_text = " ".join(words)
if wordcloud_text.strip():
    wc = WordCloud(width=800, height=400, background_color="white", stopwords=stopwords_ru).generate(wordcloud_text)
    plt.figure(figsize=(12, 6))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    st.pyplot(plt.gcf())
else:
    st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±–ª–∞–∫–∞ —Å–ª–æ–≤.")
